# CLIP PyTorch

<p align="center">
  <img src="CLIP.png" alt="CLIP" style="display:block; margin:auto; width:750px;" />
</p>

PyTorch implementation of CLIP (Contrastive Language-Image Pre-Training).

[CLIP](https://arxiv.org/abs/2103.00020): Learning Transferable Visual Models From Natural Language Supervision.

CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs.
